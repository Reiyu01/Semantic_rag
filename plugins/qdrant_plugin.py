# -*- coding: utf-8 -*-
# Qdrant Plugin (Native client version)
# Author: Reiyu + ChatGPT

import os
import anyio
from dotenv import load_dotenv
from qdrant_client import QdrantClient
from qdrant_client.http import models
from openai import AzureOpenAI
from semantic_kernel import Kernel
from semantic_kernel.functions import kernel_function
from mcp.server.stdio import stdio_server

load_dotenv()


class RagQdrantPlugin:
    def __init__(self):
        # === åˆå§‹åŒ– Qdrant ===
        self.client = QdrantClient(host="localhost", port=6333)
        self.collection_name = os.getenv("QDRANT_COLLECTION", "faq")

        # === åˆå§‹åŒ– Azure OpenAI Embedding ===
        self.embed_client = AzureOpenAI(
            api_key=os.getenv("AZURE_API_KEY"),
            azure_endpoint=os.getenv("AZURE_ENDPOINT"),
            api_version=os.getenv("AZURE_EMBED_API_VERSION", ),
        )
        self.embed_model = os.getenv("AZURE_EMBED_DEPLOYMENT")

    def embed(self, text: str):
        """ç›´æŽ¥å‘¼å« Azure OpenAI å–å¾—å‘é‡"""
        resp = self.embed_client.embeddings.create(model=self.embed_model, input=text)
        return resp.data[0].embedding

    @kernel_function(
        name="faq_lookup",
        description="å¾ž Qdrant å‘é‡è³‡æ–™åº«ä¸­æŸ¥è©¢æœ€ç›¸é—œçš„å…§å®¹ï¼Œä¸¦å›žå‚³æ‘˜è¦ã€‚"
    )
    async def faq_lookup(self, input: str) -> str:
        try:
            query_vector = self.embed(input)
            results = self.client.query_points(
                collection_name=self.collection_name,
                query=query_vector,
                limit=5,
                with_payload=True,
            )

            if not results or not results.points:
                return "âŒ æ²’æ‰¾åˆ°ç›¸é—œçµæžœã€‚"

            output = []
            for i, hit in enumerate(results.points):
                payload = hit.payload or {}
                text = payload.get("text", "(ç„¡å…§å®¹)")
                source = payload.get("file", "æœªçŸ¥æª”æ¡ˆ")
                output.append(f"{i+1}. ðŸ“˜ ä¾†æºï¼š{source}\n{text[:300]}...\n(score={hit.score:.3f})")

            return "\n\n".join(output)
        except Exception as e:
            return f"(RAG æŸ¥è©¢å¤±æ•—: {e})"


# === MCP å•Ÿå‹•å‡½æ•¸ï¼ˆå¯é¸ï¼‰===
def run() -> None:
    kernel = Kernel()
    plugin = RagQdrantPlugin()
    kernel.add_plugin(plugin, plugin_name="qdrant_faq")

    server = kernel.as_mcp_server(server_name="faq_lookup")

    async def handle_stdin():
        print("âœ… Qdrant FAQ MCP Server å•Ÿå‹•")
        async with stdio_server() as (r, w):
            await server.run(r, w, server.create_initialization_options())

    anyio.run(handle_stdin)


# # -*- coding: utf-8 -*-
# # Semantic Kernel Qdrant RAG Plugin Example (Revised)
# # Author: Reiyu + ChatGPT
# # Ref: https://learn.microsoft.com/zh-tw/semantic-kernel/concepts/vector-store-connectors/out-of-the-box-connectors/qdrant-connector

# import os
# import anyio
# from dotenv import load_dotenv
# from mcp.server.stdio import stdio_server
# from semantic_kernel import Kernel
# from semantic_kernel.functions import kernel_function
# from semantic_kernel.connectors.qdrant import QdrantStore
# from qdrant_client import AsyncQdrantClient
# from semantic_kernel.connectors.ai.open_ai import AzureTextEmbedding


# # Load environment variables
# load_dotenv()


# class RagQdrantPlugin:
#     """
#     Qdrant + Azure Embedding çš„ç°¡æ˜“ RAG Pluginï¼Œ
#     å¯ç”¨æ–¼æŸ¥è©¢ FAQ é¡žçŸ¥è­˜åº«ã€‚
#     """

#     def __init__(self):
#         # === Qdrant è¨­å®š ===
#         self.collection_name = "faq"
#         self.client = AsyncQdrantClient(host="localhost", port=6333)
#         self.vector_store = QdrantStore(client=self.client)

#         # === Azure OpenAI Embedding è¨­å®š ===
#         self.embeddings = AzureTextEmbedding(
#             deployment_name=os.getenv("AZURE_DEPLOYMENT", "text-embedding-ada-002"),
#             endpoint=os.getenv("AZURE_ENDPOINT", ""),
#             api_key=os.getenv("AZURE_API_KEY", ""),
#             api_version=os.getenv("AZURE_API_VERSION", "2023-05-15"),
#         )

#     @kernel_function(
#         name="faq_lookup",
#         description="æ ¹æ“šå•é¡Œå‘é‡æ¯”å°å¸¸è¦‹å•é¡Œè³‡æ–™åº«ä¸¦å›žå‚³æœ€ç›¸é—œçš„å›žç­”"
#     )
#     async def faq_lookup(self, question: str) -> str:
#         """
#         ç”¨æˆ¶è¼¸å…¥å•é¡Œå¾Œï¼ŒæœƒåŸ·è¡Œå‘é‡æ¯”å°ä¸¦è¼¸å‡ºæœ€ç›¸ä¼¼çš„ FAQã€‚
#         """
#         try:
#             # æŸ¥è©¢ç›¸ä¼¼æ–‡ä»¶ï¼ˆk=5ï¼‰
#             results = await self.vector_store.search(
#                 collection_name=self.collection_name,
#                 query=question,
#                 embeddings=self.embeddings,
#                 limit=5,
#             )

#             if not results:
#                 return "âŒ æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„å¸¸è¦‹å•é¡Œã€‚"

#             output_lines = []
#             for idx, r in enumerate(results):
#                 meta = r.metadata or {}
#                 q = meta.get("question", "æœªçŸ¥å•é¡Œ")
#                 a = r.text or "ï¼ˆç„¡å›žç­”å…§å®¹ï¼‰"
#                 score = round(r.score, 3) if hasattr(r, "score") else "N/A"
#                 output_lines.append(f"{idx+1}. â“ {q}\nðŸ“˜ {a}\nðŸ”¹ ç›¸ä¼¼åº¦: {score}")

#             return "\n\n".join(output_lines)

#         except Exception as e:
#             return f"âš ï¸ RAG æŸ¥è©¢ç™¼ç”ŸéŒ¯èª¤: {type(e).__name__}: {e}"


# def run() -> None:
#     """
#     å•Ÿå‹•ç‚º MCP Plugin Serverï¼Œå¯ä¾› Semantic Kernel æˆ–å¤–éƒ¨ä»£ç†å‘¼å«ã€‚
#     """
#     kernel = Kernel()
#     plugin = RagQdrantPlugin()
#     kernel.add_plugin(plugin, plugin_name="qdrant_faq")

#     async def handle_stdin():
#         print("âœ… Qdrant FAQ MCP Server æ­£åœ¨å•Ÿå‹•...")
#         async with stdio_server() as (read_stream, write_stream):
#             await kernel.run_as_mcp_server(
#                 read_stream,
#                 write_stream,
#                 server_name="qdrant_faq_server",
#             )

#     anyio.run(handle_stdin)


# if __name__ == "__main__":
#     run()









# # plugins/qdrant_faq_plugin.py

# import anyio
# from mcp.server.stdio import stdio_server
# from semantic_kernel import Kernel
# from semantic_kernel.functions import kernel_function
# from qdrant_client import QdrantClient
# from langchain_openai import AzureOpenAIEmbeddings
# from langchain_qdrant import QdrantVectorStore
# import os
# from dotenv import load_dotenv

# # Load environment variables from .env if present
# load_dotenv()


# class RagQdrantPlugin:
#     def __init__(self):
#         # Qdrant è¨­å®š
#         qdrant_url = "http://localhost:6333"
#         collection_name = "faq"

#         # Azure OpenAI çš„åƒæ•¸ï¼ˆå¾žç’°å¢ƒè®Šæ•¸è®€å–ï¼‰
#         api_key = os.environ.get("AZURE_API_KEY", "")
#         azure_endpoint = os.environ.get("AZURE_ENDPOINT", "")
#         azure_deployment = os.environ.get("AZURE_DEPLOYMENT", "text-embedding-ada-002")
#         api_version = os.environ.get("AZURE_API_VERSION", "2023-05-15")

#         # åˆå§‹åŒ– Qdrant + Azure Embeddings
#         self.client = QdrantClient(url=qdrant_url)
#         self.embeddings = AzureOpenAIEmbeddings(
#             azure_endpoint=azure_endpoint,
#             deployment=azure_deployment,
#             api_version=api_version,
#             api_key=api_key,
#         )
#         self.vector_db = QdrantVectorStore(
#             client=self.client,
#             collection_name=collection_name,
#             embedding=self.embeddings,
#         )

#     @kernel_function(
#         name="faq_lookup",
#         description="æ ¹æ“šå•é¡Œå‘é‡æ¯”å°å¸¸è¦‹å•é¡Œè³‡æ–™åº«ä¸¦å›žå‚³æœ€ç›¸é—œçš„å›žç­”"
#     )
#     async def faq_lookup(self, input: str) -> str:
#         try:
#             # åŒ…æˆéžåŒæ­¥é¿å…é˜»å¡ž
#             results = await anyio.to_thread.run_sync(
#                 lambda: self.vector_db.similarity_search(input, k=5)
#             )
#             if not results:
#                 return "(âŒ æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„å¸¸è¦‹å•é¡Œ)"

#             output = []
#             for idx, doc in enumerate(results):
#                 meta = doc.metadata or {}
#                 question = meta.get("question", "æœªçŸ¥å•é¡Œ")
#                 output.append(f"{idx+1}. â“ {question}\nðŸ“˜ {doc.page_content}")

#             return "\n\n".join(output)
#         except Exception as e:
#             return f"(RAG æœå°‹å¤±æ•—: {e})"


# def run() -> None:
#     kernel = Kernel()
#     faq_plugin = QdrantFAQ()
#     kernel.add_function("faq", faq_plugin.faq_lookup)

#     server = kernel.as_mcp_server(server_name="faq_lookup")

#     async def handle_stdin():
#         print("âœ… Qdrant FAQ MCP Server æ­£åœ¨å•Ÿå‹•...")
#         async with stdio_server() as (read_stream, write_stream):
#             await server.run(read_stream, write_stream, server.create_initialization_options())

#     anyio.run(handle_stdin)


# if __name__ == "__main__":
#     run()
